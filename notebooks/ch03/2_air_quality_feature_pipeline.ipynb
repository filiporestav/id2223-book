{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9e46aad",
   "metadata": {},
   "source": [
    "<span style=\"font-width:bold; font-size: 3rem; color:#333;\">- Part 02: Daily Feature Pipeline for Air Quality (aqicn.org) and weather (openmeteo)</span>\n",
    "\n",
    "## üóíÔ∏è This notebook is divided into the following sections:\n",
    "1. Download and Parse Data\n",
    "2. Feature Group Insertion\n",
    "\n",
    "\n",
    "__This notebook should be scheduled to run daily__\n",
    "\n",
    "In the book, we use a GitHub Action stored here:\n",
    "[.github/workflows/air-quality-daily.yml](https://github.com/featurestorebook/mlfs-book/blob/main/.github/workflows/air-quality-daily.yml)\n",
    "\n",
    "However, you are free to use any Python Orchestration tool to schedule this program to run daily."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe638c6",
   "metadata": {},
   "source": [
    "### <span style='color:#ff5f27'> üìù Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7de2e93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import hopsworks\n",
    "from functions import util\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6081d1",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üåç Get the Sensor URL, Country, City, Street names from Hopsworks </span>\n",
    "\n",
    "__Update the values in the cell below.__\n",
    "\n",
    "__These should be the same values as in notebook 1 - the feature backfill notebook__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b70cd57d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1158296\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"country\": \"sweden\", \"city\": \"sweden\", \"street\": \"sollentuna-sollentunav\\\\u00e4gen 192\", \"aqicn_url\": \"https://api.waqi.info/feed/@13984\", \"latitude\": 17.950061509561397, \"longitude\": 59.433619224293736}'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you haven't set the env variable 'HOPSWORKS_API_KEY', then uncomment the next line and enter your API key\n",
    "os.environ[\"HOPSWORKS_API_KEY\"] = \"2ZoLYydQfIz5VW5b.D5B2X2LLCmJsysb4n78mTmGgEAWzlLfrgRKcCLJXlE4iJZ9Mqhm1GhsG60PJQxls\"\n",
    "\n",
    "project = hopsworks.login()\n",
    "fs = project.get_feature_store() \n",
    "secrets = util.secrets_api(project.name)\n",
    "\n",
    "# This line will fail if you have not registered the AQI_API_KEY as a secret in Hopsworks\n",
    "AQI_API_KEY = secrets.get_secret(\"AQI_API_KEY\").value\n",
    "location_str = secrets.get_secret(\"SENSOR_LOCATION_JSON\").value\n",
    "location = json.loads(location_str)\n",
    "\n",
    "country=location['country']\n",
    "city=location['city']\n",
    "street=location['street']\n",
    "aqicn_url=location['aqicn_url']\n",
    "latitude=location['latitude']\n",
    "longitude=location['longitude']\n",
    "\n",
    "today = datetime.date.today()\n",
    "\n",
    "location_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2caf9289",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\"> üîÆ Get references to the Feature Groups </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66f5d7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve feature groups\n",
    "air_quality_fg = fs.get_feature_group(\n",
    "    name='air_quality',\n",
    "    version=1,\n",
    ")\n",
    "weather_fg = fs.get_feature_group(\n",
    "    name='weather',\n",
    "    version=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10b6ce8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7ffa41",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üå´ Retrieve Today's Air Quality data (PM2.5) from the AQI API</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f681af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-18 20:18:10,584 ERROR: [Errno 2] Opening HDFS file '/apps/hive/warehouse/orestavf_featurestore.db/air_quality_1/.hoodie/hoodie.properties' failed. Detail: [errno 2] No such file or directory. Detail: Python exception: FlyingDuckException. gRPC client debug context: UNKNOWN:Error received from peer ipv4:3.19.160.248:5005 {grpc_message:\"[Errno 2] Opening HDFS file \\'/apps/hive/warehouse/orestavf_featurestore.db/air_quality_1/.hoodie/hoodie.properties\\' failed. Detail: [errno 2] No such file or directory. Detail: Python exception: FlyingDuckException\", grpc_status:2, created_time:\"2024-11-18T20:18:10.584626+01:00\"}. Client context: IOError: Server never sent a data message. Detail: Internal\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/filip/id2223-book/venv/lib/python3.11/site-packages/hsfs/core/arrow_flight_client.py\", line 347, in afs_error_handler_wrapper\n",
      "    return func(instance, *args, **kw)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/filip/id2223-book/venv/lib/python3.11/site-packages/hsfs/core/arrow_flight_client.py\", line 405, in read_query\n",
      "    return self._get_dataset(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/filip/id2223-book/venv/lib/python3.11/site-packages/retrying.py\", line 56, in wrapped_f\n",
      "    return Retrying(*dargs, **dkw).call(f, *args, **kw)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/filip/id2223-book/venv/lib/python3.11/site-packages/retrying.py\", line 257, in call\n",
      "    return attempt.get(self._wrap_exception)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/filip/id2223-book/venv/lib/python3.11/site-packages/retrying.py\", line 301, in get\n",
      "    six.reraise(self.value[0], self.value[1], self.value[2])\n",
      "  File \"/Users/filip/id2223-book/venv/lib/python3.11/site-packages/six.py\", line 719, in reraise\n",
      "    raise value\n",
      "  File \"/Users/filip/id2223-book/venv/lib/python3.11/site-packages/retrying.py\", line 251, in call\n",
      "    attempt = Attempt(fn(*args, **kwargs), attempt_number, False)\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/filip/id2223-book/venv/lib/python3.11/site-packages/hsfs/core/arrow_flight_client.py\", line 396, in _get_dataset\n",
      "    reader = self._connection.do_get(info.endpoints[0].ticket, options)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"pyarrow/_flight.pyx\", line 1633, in pyarrow._flight.FlightClient.do_get\n",
      "  File \"pyarrow/_flight.pyx\", line 58, in pyarrow._flight.check_flight_status\n",
      "pyarrow._flight.FlightServerError: [Errno 2] Opening HDFS file '/apps/hive/warehouse/orestavf_featurestore.db/air_quality_1/.hoodie/hoodie.properties' failed. Detail: [errno 2] No such file or directory. Detail: Python exception: FlyingDuckException. gRPC client debug context: UNKNOWN:Error received from peer ipv4:3.19.160.248:5005 {grpc_message:\"[Errno 2] Opening HDFS file \\'/apps/hive/warehouse/orestavf_featurestore.db/air_quality_1/.hoodie/hoodie.properties\\' failed. Detail: [errno 2] No such file or directory. Detail: Python exception: FlyingDuckException\", grpc_status:2, created_time:\"2024-11-18T20:18:10.584626+01:00\"}. Client context: IOError: Server never sent a data message. Detail: Internal\n",
      "Error: Reading data from Hopsworks, using Hopsworks Feature Query Service           \n",
      "Attempt 1 failed: Could not read data using Hopsworks Feature Query Service. If the issue persists, use read_options={\"use_hive\": True} instead.\n",
      "2024-11-18 20:18:16,466 ERROR: [Errno 2] Opening HDFS file '/apps/hive/warehouse/orestavf_featurestore.db/air_quality_1/.hoodie/hoodie.properties' failed. Detail: [errno 2] No such file or directory. Detail: Python exception: FlyingDuckException. gRPC client debug context: UNKNOWN:Error received from peer ipv4:3.19.160.248:5005 {created_time:\"2024-11-18T20:18:16.466624+01:00\", grpc_status:2, grpc_message:\"[Errno 2] Opening HDFS file \\'/apps/hive/warehouse/orestavf_featurestore.db/air_quality_1/.hoodie/hoodie.properties\\' failed. Detail: [errno 2] No such file or directory. Detail: Python exception: FlyingDuckException\"}. Client context: IOError: Server never sent a data message. Detail: Internal\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/filip/id2223-book/venv/lib/python3.11/site-packages/hsfs/core/arrow_flight_client.py\", line 347, in afs_error_handler_wrapper\n",
      "    return func(instance, *args, **kw)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/filip/id2223-book/venv/lib/python3.11/site-packages/hsfs/core/arrow_flight_client.py\", line 405, in read_query\n",
      "    return self._get_dataset(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/filip/id2223-book/venv/lib/python3.11/site-packages/retrying.py\", line 56, in wrapped_f\n",
      "    return Retrying(*dargs, **dkw).call(f, *args, **kw)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/filip/id2223-book/venv/lib/python3.11/site-packages/retrying.py\", line 257, in call\n",
      "    return attempt.get(self._wrap_exception)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/filip/id2223-book/venv/lib/python3.11/site-packages/retrying.py\", line 301, in get\n",
      "    six.reraise(self.value[0], self.value[1], self.value[2])\n",
      "  File \"/Users/filip/id2223-book/venv/lib/python3.11/site-packages/six.py\", line 719, in reraise\n",
      "    raise value\n",
      "  File \"/Users/filip/id2223-book/venv/lib/python3.11/site-packages/retrying.py\", line 251, in call\n",
      "    attempt = Attempt(fn(*args, **kwargs), attempt_number, False)\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/filip/id2223-book/venv/lib/python3.11/site-packages/hsfs/core/arrow_flight_client.py\", line 396, in _get_dataset\n",
      "    reader = self._connection.do_get(info.endpoints[0].ticket, options)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"pyarrow/_flight.pyx\", line 1633, in pyarrow._flight.FlightClient.do_get\n",
      "  File \"pyarrow/_flight.pyx\", line 58, in pyarrow._flight.check_flight_status\n",
      "pyarrow._flight.FlightServerError: [Errno 2] Opening HDFS file '/apps/hive/warehouse/orestavf_featurestore.db/air_quality_1/.hoodie/hoodie.properties' failed. Detail: [errno 2] No such file or directory. Detail: Python exception: FlyingDuckException. gRPC client debug context: UNKNOWN:Error received from peer ipv4:3.19.160.248:5005 {created_time:\"2024-11-18T20:18:16.466624+01:00\", grpc_status:2, grpc_message:\"[Errno 2] Opening HDFS file \\'/apps/hive/warehouse/orestavf_featurestore.db/air_quality_1/.hoodie/hoodie.properties\\' failed. Detail: [errno 2] No such file or directory. Detail: Python exception: FlyingDuckException\"}. Client context: IOError: Server never sent a data message. Detail: Internal\n",
      "Error: Reading data from Hopsworks, using Hopsworks Feature Query Service           \n",
      "Attempt 2 failed: Could not read data using Hopsworks Feature Query Service. If the issue persists, use read_options={\"use_hive\": True} instead.\n",
      "2024-11-18 20:18:22,276 ERROR: [Errno 2] Opening HDFS file '/apps/hive/warehouse/orestavf_featurestore.db/air_quality_1/.hoodie/hoodie.properties' failed. Detail: [errno 2] No such file or directory. Detail: Python exception: FlyingDuckException. gRPC client debug context: UNKNOWN:Error received from peer ipv4:3.19.160.248:5005 {grpc_message:\"[Errno 2] Opening HDFS file \\'/apps/hive/warehouse/orestavf_featurestore.db/air_quality_1/.hoodie/hoodie.properties\\' failed. Detail: [errno 2] No such file or directory. Detail: Python exception: FlyingDuckException\", grpc_status:2, created_time:\"2024-11-18T20:18:22.276217+01:00\"}. Client context: IOError: Server never sent a data message. Detail: Internal\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/filip/id2223-book/venv/lib/python3.11/site-packages/hsfs/core/arrow_flight_client.py\", line 347, in afs_error_handler_wrapper\n",
      "    return func(instance, *args, **kw)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/filip/id2223-book/venv/lib/python3.11/site-packages/hsfs/core/arrow_flight_client.py\", line 405, in read_query\n",
      "    return self._get_dataset(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/filip/id2223-book/venv/lib/python3.11/site-packages/retrying.py\", line 56, in wrapped_f\n",
      "    return Retrying(*dargs, **dkw).call(f, *args, **kw)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/filip/id2223-book/venv/lib/python3.11/site-packages/retrying.py\", line 257, in call\n",
      "    return attempt.get(self._wrap_exception)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/filip/id2223-book/venv/lib/python3.11/site-packages/retrying.py\", line 301, in get\n",
      "    six.reraise(self.value[0], self.value[1], self.value[2])\n",
      "  File \"/Users/filip/id2223-book/venv/lib/python3.11/site-packages/six.py\", line 719, in reraise\n",
      "    raise value\n",
      "  File \"/Users/filip/id2223-book/venv/lib/python3.11/site-packages/retrying.py\", line 251, in call\n",
      "    attempt = Attempt(fn(*args, **kwargs), attempt_number, False)\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/filip/id2223-book/venv/lib/python3.11/site-packages/hsfs/core/arrow_flight_client.py\", line 396, in _get_dataset\n",
      "    reader = self._connection.do_get(info.endpoints[0].ticket, options)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"pyarrow/_flight.pyx\", line 1633, in pyarrow._flight.FlightClient.do_get\n",
      "  File \"pyarrow/_flight.pyx\", line 58, in pyarrow._flight.check_flight_status\n",
      "pyarrow._flight.FlightServerError: [Errno 2] Opening HDFS file '/apps/hive/warehouse/orestavf_featurestore.db/air_quality_1/.hoodie/hoodie.properties' failed. Detail: [errno 2] No such file or directory. Detail: Python exception: FlyingDuckException. gRPC client debug context: UNKNOWN:Error received from peer ipv4:3.19.160.248:5005 {grpc_message:\"[Errno 2] Opening HDFS file \\'/apps/hive/warehouse/orestavf_featurestore.db/air_quality_1/.hoodie/hoodie.properties\\' failed. Detail: [errno 2] No such file or directory. Detail: Python exception: FlyingDuckException\", grpc_status:2, created_time:\"2024-11-18T20:18:22.276217+01:00\"}. Client context: IOError: Server never sent a data message. Detail: Internal\n",
      "Error: Reading data from Hopsworks, using Hopsworks Feature Query Service           \n",
      "Attempt 3 failed: Could not read data using Hopsworks Feature Query Service. If the issue persists, use read_options={\"use_hive\": True} instead.\n",
      "Failed to read feature group data after 3 attempts.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'air_quality_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Ensure 'date' columns are in datetime format\u001b[39;00m\n\u001b[1;32m     21\u001b[0m aq_today_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(aq_today_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m], utc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 22\u001b[0m air_quality_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[43mair_quality_df\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m], utc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Convert both 'date' columns to the same timezone (e.g., Europe/Stockholm)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m aq_today_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m aq_today_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mtz_convert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEurope/Stockholm\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'air_quality_df' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the air quality feature group into a pandas dataframe\n",
    "#air_quality_df = air_quality_fg.read(read_options={\"use_hive\": True})\n",
    "air_quality_df = air_quality_fg.read()\n",
    "\n",
    "# Fetch today's data\n",
    "aq_today_df = util.get_pm25(aqicn_url, country, city, street, today, AQI_API_KEY)\n",
    "\n",
    "# Ensure 'date' columns are in datetime format\n",
    "aq_today_df['date'] = pd.to_datetime(aq_today_df['date'], utc=True)\n",
    "air_quality_df['date'] = pd.to_datetime(air_quality_df['date'], utc=True)\n",
    "\n",
    "# Convert both 'date' columns to the same timezone (e.g., Europe/Stockholm)\n",
    "aq_today_df['date'] = aq_today_df['date'].dt.tz_convert('Europe/Stockholm')\n",
    "air_quality_df['date'] = air_quality_df['date'].dt.tz_convert('Europe/Stockholm')\n",
    "\n",
    "# Normalize the 'date' columns to day precision to ensure alignment\n",
    "aq_today_df['date'] = aq_today_df['date'].dt.normalize()\n",
    "air_quality_df['date'] = air_quality_df['date'].dt.normalize()\n",
    "\n",
    "# Debugging: Print unique dates for verification\n",
    "print(\"Unique dates in aq_today_df:\", aq_today_df['date'].unique())\n",
    "print(\"Unique dates in air_quality_df:\", air_quality_df['date'].unique())\n",
    "\n",
    "# Check for matching dates between the two DataFrames\n",
    "matching_dates = set(aq_today_df['date']).intersection(set(air_quality_df['date']))\n",
    "print(\"Matching dates:\", matching_dates)\n",
    "\n",
    "# Merge the lag columns into the aq_today_df\n",
    "aq_today_df = aq_today_df.merge(\n",
    "    air_quality_df[['date', 'pm25_lag_1', 'pm25_lag_2', 'pm25_lag_3']],\n",
    "    on='date',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Debugging: Check if the merge was successful\n",
    "print(\"aq_today_df after merge:\")\n",
    "print(aq_today_df.sort_values('date'))\n",
    "\n",
    "# Convert lagged columns to float32, handling errors gracefully\n",
    "for lag_col in ['pm25_lag_1', 'pm25_lag_2', 'pm25_lag_3']:\n",
    "    aq_today_df[lag_col] = aq_today_df[lag_col].astype('float32', errors='ignore')\n",
    "\n",
    "# Optional: Check for rows with missing lag data in air_quality_df\n",
    "missing_lags = air_quality_df[air_quality_df[['pm25_lag_1', 'pm25_lag_2', 'pm25_lag_3']].isna().any(axis=1)]\n",
    "print(\"Rows with missing lag data in air_quality_df:\")\n",
    "print(missing_lags)\n",
    "\n",
    "# Final output\n",
    "print(\"Final aq_today_df:\")\n",
    "print(aq_today_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e24eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1 entries, 0 to 0\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype                           \n",
      "---  ------      --------------  -----                           \n",
      " 0   pm25        1 non-null      float32                         \n",
      " 1   country     1 non-null      object                          \n",
      " 2   city        1 non-null      object                          \n",
      " 3   street      1 non-null      object                          \n",
      " 4   date        1 non-null      datetime64[ns, Europe/Stockholm]\n",
      " 5   url         1 non-null      object                          \n",
      " 6   pm25_lag_1  0 non-null      float32                         \n",
      " 7   pm25_lag_2  0 non-null      float32                         \n",
      " 8   pm25_lag_3  0 non-null      float32                         \n",
      "dtypes: datetime64[ns, Europe/Stockholm](1), float32(4), object(4)\n",
      "memory usage: 184.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "aq_today_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af845ab6",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üå¶ Get Weather Forecast data</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ecb3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates 18.0¬∞N 59.5¬∞E\n",
      "Elevation 0.0 m asl\n",
      "Timezone None None\n",
      "Timezone difference to GMT+0 0 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>temperature_2m_mean</th>\n",
       "      <th>precipitation_sum</th>\n",
       "      <th>wind_speed_10m_max</th>\n",
       "      <th>wind_direction_10m_dominant</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-11-18</td>\n",
       "      <td>27.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.406927</td>\n",
       "      <td>66.317902</td>\n",
       "      <td>sweden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-11-19</td>\n",
       "      <td>28.299999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.071098</td>\n",
       "      <td>68.962418</td>\n",
       "      <td>sweden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-11-20</td>\n",
       "      <td>27.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.518847</td>\n",
       "      <td>72.474342</td>\n",
       "      <td>sweden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-11-21</td>\n",
       "      <td>27.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.240198</td>\n",
       "      <td>51.499329</td>\n",
       "      <td>sweden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-11-22</td>\n",
       "      <td>27.650000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.595861</td>\n",
       "      <td>59.237358</td>\n",
       "      <td>sweden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-11-23</td>\n",
       "      <td>27.200001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.768586</td>\n",
       "      <td>40.425995</td>\n",
       "      <td>sweden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024-11-24</td>\n",
       "      <td>27.650000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.246826</td>\n",
       "      <td>47.202621</td>\n",
       "      <td>sweden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024-11-25</td>\n",
       "      <td>27.850000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.398056</td>\n",
       "      <td>77.366646</td>\n",
       "      <td>sweden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2024-11-26</td>\n",
       "      <td>27.299999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.068459</td>\n",
       "      <td>73.113129</td>\n",
       "      <td>sweden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2024-11-27</td>\n",
       "      <td>27.549999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.129883</td>\n",
       "      <td>45.690197</td>\n",
       "      <td>sweden</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  temperature_2m_mean  precipitation_sum  wind_speed_10m_max  \\\n",
       "0 2024-11-18            27.750000                0.0           22.406927   \n",
       "1 2024-11-19            28.299999                0.0           25.071098   \n",
       "2 2024-11-20            27.600000                0.0           21.518847   \n",
       "3 2024-11-21            27.600000                0.0           20.240198   \n",
       "4 2024-11-22            27.650000                0.0           17.595861   \n",
       "5 2024-11-23            27.200001                0.0           12.768586   \n",
       "6 2024-11-24            27.650000                0.0           13.246826   \n",
       "7 2024-11-25            27.850000                0.0           21.398056   \n",
       "8 2024-11-26            27.299999                0.0           21.068459   \n",
       "9 2024-11-27            27.549999                0.0           21.129883   \n",
       "\n",
       "   wind_direction_10m_dominant    city  \n",
       "0                    66.317902  sweden  \n",
       "1                    68.962418  sweden  \n",
       "2                    72.474342  sweden  \n",
       "3                    51.499329  sweden  \n",
       "4                    59.237358  sweden  \n",
       "5                    40.425995  sweden  \n",
       "6                    47.202621  sweden  \n",
       "7                    77.366646  sweden  \n",
       "8                    73.113129  sweden  \n",
       "9                    45.690197  sweden  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_df = util.get_hourly_weather_forecast(city, latitude, longitude)\n",
    "hourly_df = hourly_df.set_index('date')\n",
    "\n",
    "# We will only make 1 daily prediction, so we will replace the hourly forecasts with a single daily forecast\n",
    "# We only want the daily weather data, so only get weather at 12:00\n",
    "daily_df = hourly_df.between_time('11:59', '12:01')\n",
    "daily_df = daily_df.reset_index()\n",
    "daily_df['date'] = pd.to_datetime(daily_df['date']).dt.date\n",
    "daily_df['date'] = pd.to_datetime(daily_df['date'])\n",
    "daily_df['city'] = city\n",
    "daily_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c563109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 6 columns):\n",
      " #   Column                       Non-Null Count  Dtype         \n",
      "---  ------                       --------------  -----         \n",
      " 0   date                         10 non-null     datetime64[ns]\n",
      " 1   temperature_2m_mean          10 non-null     float32       \n",
      " 2   precipitation_sum            10 non-null     float32       \n",
      " 3   wind_speed_10m_max           10 non-null     float32       \n",
      " 4   wind_direction_10m_dominant  10 non-null     float32       \n",
      " 5   city                         10 non-null     object        \n",
      "dtypes: datetime64[ns](1), float32(4), object(1)\n",
      "memory usage: 448.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "daily_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1f5008",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style=\"color:#ff5f27;\">‚¨ÜÔ∏è Uploading new data to the Feature Store</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9de5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-18 12:16:40,977 INFO: \t4 expectation(s) included in expectation_suite.\n",
      "Validation failed.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1158296/fs/1148999/fg/1351123\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7696d432e2bb46f785fdea9380984276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading Dataframe: 0.00% |          | Rows 0/1 | Elapsed Time: 00:00 | Remaining Time: ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: air_quality_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/1158296/jobs/named/air_quality_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<hsfs.core.job.Job at 0x2ba3a0390>,\n",
       " {\n",
       "   \"success\": false,\n",
       "   \"results\": [\n",
       "     {\n",
       "       \"success\": false,\n",
       "       \"expectation_config\": {\n",
       "         \"expectation_type\": \"expect_column_min_to_be_between\",\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"pm25_lag_3\",\n",
       "           \"min_value\": -0.1,\n",
       "           \"max_value\": 500.0,\n",
       "           \"strict_min\": true\n",
       "         },\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 675010\n",
       "         }\n",
       "       },\n",
       "       \"result\": {\n",
       "         \"observed_value\": null,\n",
       "         \"element_count\": 1,\n",
       "         \"missing_count\": null,\n",
       "         \"missing_percent\": null\n",
       "       },\n",
       "       \"meta\": {\n",
       "         \"ingestionResult\": \"INGESTED\",\n",
       "         \"validationTime\": \"2024-11-18T11:16:40.000977Z\"\n",
       "       },\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       }\n",
       "     },\n",
       "     {\n",
       "       \"success\": false,\n",
       "       \"expectation_config\": {\n",
       "         \"expectation_type\": \"expect_column_min_to_be_between\",\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"pm25_lag_1\",\n",
       "           \"min_value\": -0.1,\n",
       "           \"max_value\": 500.0,\n",
       "           \"strict_min\": true\n",
       "         },\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 675007\n",
       "         }\n",
       "       },\n",
       "       \"result\": {\n",
       "         \"observed_value\": null,\n",
       "         \"element_count\": 1,\n",
       "         \"missing_count\": null,\n",
       "         \"missing_percent\": null\n",
       "       },\n",
       "       \"meta\": {\n",
       "         \"ingestionResult\": \"INGESTED\",\n",
       "         \"validationTime\": \"2024-11-18T11:16:40.000977Z\"\n",
       "       },\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       }\n",
       "     },\n",
       "     {\n",
       "       \"success\": true,\n",
       "       \"expectation_config\": {\n",
       "         \"expectation_type\": \"expect_column_min_to_be_between\",\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"pm25\",\n",
       "           \"min_value\": -0.1,\n",
       "           \"max_value\": 500.0,\n",
       "           \"strict_min\": true\n",
       "         },\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 675009\n",
       "         }\n",
       "       },\n",
       "       \"result\": {\n",
       "         \"observed_value\": 11.0,\n",
       "         \"element_count\": 1,\n",
       "         \"missing_count\": null,\n",
       "         \"missing_percent\": null\n",
       "       },\n",
       "       \"meta\": {\n",
       "         \"ingestionResult\": \"INGESTED\",\n",
       "         \"validationTime\": \"2024-11-18T11:16:40.000977Z\"\n",
       "       },\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       }\n",
       "     },\n",
       "     {\n",
       "       \"success\": false,\n",
       "       \"expectation_config\": {\n",
       "         \"expectation_type\": \"expect_column_min_to_be_between\",\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"pm25_lag_2\",\n",
       "           \"min_value\": -0.1,\n",
       "           \"max_value\": 500.0,\n",
       "           \"strict_min\": true\n",
       "         },\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 675008\n",
       "         }\n",
       "       },\n",
       "       \"result\": {\n",
       "         \"observed_value\": null,\n",
       "         \"element_count\": 1,\n",
       "         \"missing_count\": null,\n",
       "         \"missing_percent\": null\n",
       "       },\n",
       "       \"meta\": {\n",
       "         \"ingestionResult\": \"INGESTED\",\n",
       "         \"validationTime\": \"2024-11-18T11:16:40.000977Z\"\n",
       "       },\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       }\n",
       "     }\n",
       "   ],\n",
       "   \"evaluation_parameters\": {},\n",
       "   \"statistics\": {\n",
       "     \"evaluated_expectations\": 4,\n",
       "     \"successful_expectations\": 1,\n",
       "     \"unsuccessful_expectations\": 3,\n",
       "     \"success_percent\": 25.0\n",
       "   },\n",
       "   \"meta\": {\n",
       "     \"great_expectations_version\": \"0.18.12\",\n",
       "     \"expectation_suite_name\": \"aq_expectation_suite\",\n",
       "     \"run_id\": {\n",
       "       \"run_name\": null,\n",
       "       \"run_time\": \"2024-11-18T12:16:40.977516+01:00\"\n",
       "     },\n",
       "     \"batch_kwargs\": {\n",
       "       \"ge_batch_id\": \"95e0cf7a-a59e-11ef-bccd-72026e19cdc6\"\n",
       "     },\n",
       "     \"batch_markers\": {},\n",
       "     \"batch_parameters\": {},\n",
       "     \"validation_time\": \"20241118T111640.977382Z\",\n",
       "     \"expectation_suite_meta\": {\n",
       "       \"great_expectations_version\": \"0.18.12\"\n",
       "     }\n",
       "   }\n",
       " })"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert new data\n",
    "air_quality_fg.insert(aq_today_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d491b0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-18 12:16:50,648 INFO: \t2 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1158296/fs/1148999/fg/1353039\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b97632b195f24b5da714e0ea065e069e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading Dataframe: 0.00% |          | Rows 0/10 | Elapsed Time: 00:00 | Remaining Time: ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: weather_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/1158296/jobs/named/weather_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<hsfs.core.job.Job at 0x2ba394350>,\n",
       " {\n",
       "   \"success\": true,\n",
       "   \"results\": [\n",
       "     {\n",
       "       \"success\": true,\n",
       "       \"expectation_config\": {\n",
       "         \"expectation_type\": \"expect_column_min_to_be_between\",\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"precipitation_sum\",\n",
       "           \"min_value\": -0.1,\n",
       "           \"max_value\": 1000.0,\n",
       "           \"strict_min\": true\n",
       "         },\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 676869\n",
       "         }\n",
       "       },\n",
       "       \"result\": {\n",
       "         \"observed_value\": 0.0,\n",
       "         \"element_count\": 10,\n",
       "         \"missing_count\": null,\n",
       "         \"missing_percent\": null\n",
       "       },\n",
       "       \"meta\": {\n",
       "         \"ingestionResult\": \"INGESTED\",\n",
       "         \"validationTime\": \"2024-11-18T11:16:50.000647Z\"\n",
       "       },\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       }\n",
       "     },\n",
       "     {\n",
       "       \"success\": true,\n",
       "       \"expectation_config\": {\n",
       "         \"expectation_type\": \"expect_column_min_to_be_between\",\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"wind_speed_10m_max\",\n",
       "           \"min_value\": -0.1,\n",
       "           \"max_value\": 1000.0,\n",
       "           \"strict_min\": true\n",
       "         },\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 676870\n",
       "         }\n",
       "       },\n",
       "       \"result\": {\n",
       "         \"observed_value\": 12.768587112426758,\n",
       "         \"element_count\": 10,\n",
       "         \"missing_count\": null,\n",
       "         \"missing_percent\": null\n",
       "       },\n",
       "       \"meta\": {\n",
       "         \"ingestionResult\": \"INGESTED\",\n",
       "         \"validationTime\": \"2024-11-18T11:16:50.000647Z\"\n",
       "       },\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       }\n",
       "     }\n",
       "   ],\n",
       "   \"evaluation_parameters\": {},\n",
       "   \"statistics\": {\n",
       "     \"evaluated_expectations\": 2,\n",
       "     \"successful_expectations\": 2,\n",
       "     \"unsuccessful_expectations\": 0,\n",
       "     \"success_percent\": 100.0\n",
       "   },\n",
       "   \"meta\": {\n",
       "     \"great_expectations_version\": \"0.18.12\",\n",
       "     \"expectation_suite_name\": \"weather_expectation_suite\",\n",
       "     \"run_id\": {\n",
       "       \"run_name\": null,\n",
       "       \"run_time\": \"2024-11-18T12:16:50.647966+01:00\"\n",
       "     },\n",
       "     \"batch_kwargs\": {\n",
       "       \"ge_batch_id\": \"9ba4d5aa-a59e-11ef-bccd-72026e19cdc6\"\n",
       "     },\n",
       "     \"batch_markers\": {},\n",
       "     \"batch_parameters\": {},\n",
       "     \"validation_time\": \"20241118T111650.647814Z\",\n",
       "     \"expectation_suite_meta\": {\n",
       "       \"great_expectations_version\": \"0.18.12\"\n",
       "     }\n",
       "   }\n",
       " })"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert new data\n",
    "weather_fg.insert(daily_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83e9e2d",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">‚è≠Ô∏è **Next:** Part 03: Training Pipeline\n",
    " </span> \n",
    "\n",
    "In the following notebook you will read from a feature group and create training dataset within the feature store\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
